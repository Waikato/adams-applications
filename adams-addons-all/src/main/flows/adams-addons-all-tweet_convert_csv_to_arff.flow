# Project: adams
# Date: 2019-12-19 11:34:59
# User: fracpete
# Charset: UTF-8
# Modules: adams-access,adams-audio,adams-cntk,adams-cntk-weka,adams-compress,adams-core,adams-cqengine,adams-db,adams-event,adams-excel,adams-ffmpeg,adams-gnuplot,adams-groovy,adams-groovy-rest,adams-groovy-webservice,adams-heatmap,adams-html,adams-image-webservice,adams-imaging,adams-imaging-boofcv,adams-imaging-imagemagick,adams-imaging-openimaj,adams-jooq,adams-json,adams-jython,adams-latex,adams-maps,adams-math,adams-meka,adams-meka-webservice,adams-meta,adams-ml,adams-moa,adams-mongodb,adams-net,adams-nlp,adams-odf,adams-osm,adams-pdf,adams-python,adams-python-weka,adams-r,adams-rabbitmq,adams-rabbitmq-rats,adams-random,adams-rats-core,adams-rats-net,adams-rats-rest,adams-rats-webservice,adams-rest,adams-rsync,adams-security,adams-spreadsheet,adams-tensorflow,adams-terminal,adams-timeseries,adams-twitter,adams-twitter-rats,adams-video,adams-visualstats,adams-webservice,adams-webservice-core,adams-weka,adams-weka-nd4j,adams-weka-webservice,adams-xml,adams-yaml
#
adams.flow.control.Flow -annotation "Converts tweet archives in CSV to ARFF (can be compressed)" -flow-execution-listener adams.flow.execution.NullListener
 adams.flow.standalone.CallableActors
  adams.flow.sink.ProgressBar -writer adams.gui.print.NullWriter -max @{max}
 adams.flow.source.Start
 adams.flow.control.Trigger -name "prompt user"
  adams.flow.source.EnterManyValues -stop-if-canceled true -value "adams.flow.source.valuedefinition.DefaultValueDefinition -name dir -display \"Directory with tweet archives\" -type DIRECTORY_ABSOLUTE -default-value ${FLOWS}/output" -value "adams.flow.source.valuedefinition.DefaultValueDefinition -name arff_dir -display \"Ouput dir for ARFF files\" -type DIRECTORY_ABSOLUTE -default-value ${FLOWS}/output"
  adams.flow.transformer.SpreadSheetVariableRowIterator
 adams.flow.control.Trigger -name select/process
  adams.flow.standalone.SetVariable -var-name count -var-value 0
  adams.flow.source.SelectFile -output-array true -stop-if-canceled true -initial-dir @{dir} -extension csv,csv.gz
  adams.flow.control.Tee -name "# files"
   adams.flow.transformer.ArrayLength
   adams.flow.transformer.SetVariable -var-name max
  adams.flow.transformer.ArrayToSequence
  adams.flow.control.Tee -name "relation name"
   adams.flow.transformer.BaseName -remove-extensions true
   adams.flow.transformer.SetVariable -var-name relation
  adams.flow.control.Tee -name "output filename"
   adams.flow.transformer.BaseName
   adams.flow.transformer.PrependDir -prefix @{arff_dir}
   adams.flow.transformer.Convert -conversion "adams.data.conversion.ReplaceFileExtension -extension .arff"
   adams.flow.transformer.SetVariable -var-name outfile
   adams.flow.transformer.Convert -name "Convert (2)" -conversion "adams.data.conversion.ReplaceFileExtension -extension .arff.gz"
   adams.flow.transformer.SetVariable -name "SetVariable (2)" -var-name outfilecomp
  adams.flow.control.Tee -name convert
   adams.flow.transformer.SpreadSheetFileReader -reader "adams.data.io.input.CsvSpreadSheetReader -data-row-type adams.data.spreadsheet.DenseDataRow -spreadsheet-type adams.data.spreadsheet.DefaultSpreadSheet -text-columns first-last -chunk-size 100000 -parse-formulas false -skip-differing-rows true"
   adams.flow.transformer.Convert -conversion "adams.data.conversion.SpreadSheetToWekaInstances -max-labels -1"
   adams.flow.transformer.WekaRenameRelation -replace @{relation}
   adams.flow.transformer.WekaInstanceBuffer -operation INSTANCES_TO_INSTANCE
   adams.flow.transformer.WekaInstanceDumper -prefix @{outfile}
  adams.flow.control.Trigger -name compress
   adams.flow.source.Variable -var-name outfile -conversion adams.data.conversion.StringToString
   adams.flow.transformer.GZIP -remove true -output @{outfilecomp} -buffer 10240
  adams.flow.control.Tee -name progress
   adams.flow.transformer.IncVariable -var-name count -output-variable-value true
   adams.flow.sink.CallableSink -callable ProgressBar